{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c468a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T13:44:24.154298Z",
     "start_time": "2022-02-26T13:44:17.510923Z"
    },
    "id": "717c468a"
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install torchvision \n",
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3211ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:27:08.567073Z",
     "start_time": "2022-02-27T09:25:52.238959Z"
    },
    "id": "b3211ceb"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchtext.legacy import data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7f0e38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:27:14.926632Z",
     "start_time": "2022-02-27T10:27:14.518594Z"
    },
    "id": "8e7f0e38"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy',\n",
    "                  tokenizer_language = 'en_core_web_sm',\n",
    "                  include_lengths = True)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c337cf0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:28:02.281148Z",
     "start_time": "2022-02-27T10:28:02.062259Z"
    },
    "id": "c337cf0a"
   },
   "outputs": [],
   "source": [
    "fields_train = [('text', TEXT), ('label', LABEL)]\n",
    "train_data = data.TabularDataset(path = 'products_sentiment_train.tsv',\n",
    "                                        format = 'tsv',\n",
    "                                        fields = fields_train,\n",
    "                                        skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a414ce9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:28:10.497813Z",
     "start_time": "2022-02-27T10:28:10.439418Z"
    },
    "id": "a414ce9f"
   },
   "outputs": [],
   "source": [
    "fields_test = [(None, None), ('text', TEXT)]\n",
    "test_data = data.TabularDataset(path = 'products_sentiment_test.tsv',\n",
    "                                        format = 'tsv',\n",
    "                                        fields = fields_test,\n",
    "                                        skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ooQF5tDl6HuB",
   "metadata": {
    "id": "ooQF5tDl6HuB"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state = np.random.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc90e65c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:30:29.023925Z",
     "start_time": "2022-02-27T10:29:59.426178Z"
    },
    "id": "bc90e65c"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "xTVco0gFwT_7",
   "metadata": {
    "id": "xTVco0gFwT_7"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bedc8a85",
   "metadata": {
    "id": "bedc8a85"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3IYeeLgyKNA",
   "metadata": {
    "id": "f3IYeeLgyKNA"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "SIFPoGm7yKfl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIFPoGm7yKfl",
    "outputId": "0f9c6660-ae22-4d62-cc90-d62b7c2ffe52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5636, -0.6551,  2.9162,  ...,  1.4803,  0.0057,  1.1102],\n",
       "        [-0.8177, -0.5299,  1.5776,  ...,  1.0584,  1.8107, -2.1398],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.0205, -0.4512,  0.6993,  ...,  0.0381,  0.2786,  0.2889],\n",
       "        [-0.3916,  0.0405, -0.3635,  ..., -0.0546, -0.0856, -0.0657],\n",
       "        [-0.0540,  0.0612,  0.5509,  ..., -0.2635, -0.3830, -1.6478]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7gTB0u2FyUV1",
   "metadata": {
    "id": "7gTB0u2FyUV1"
   },
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "zN6NeBm7yX_b",
   "metadata": {
    "id": "zN6NeBm7yX_b"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "h1swHoL8ydJx",
   "metadata": {
    "id": "h1swHoL8ydJx"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ZcVsoFF4yfI_",
   "metadata": {
    "id": "ZcVsoFF4yfI_"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6aWvoYkyhM1",
   "metadata": {
    "id": "d6aWvoYkyhM1"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "GCn-fHwPymIZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCn-fHwPymIZ",
    "outputId": "dbb8d578-b74b-4524-8de1-526d0850b843"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:01<00:14,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.653 | Train Acc: 63.84%\n",
      "\t Val. Loss: 0.661 |  Val. Acc: 59.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2/15 [00:01<00:12,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.614 | Train Acc: 65.97%\n",
      "\t Val. Loss: 0.693 |  Val. Acc: 52.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 3/15 [00:02<00:11,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.586 | Train Acc: 67.39%\n",
      "\t Val. Loss: 0.582 |  Val. Acc: 72.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 4/15 [00:03<00:10,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.507 | Train Acc: 74.56%\n",
      "\t Val. Loss: 0.552 |  Val. Acc: 72.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 5/15 [00:04<00:09,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.465 | Train Acc: 77.26%\n",
      "\t Val. Loss: 0.515 |  Val. Acc: 74.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 6/15 [00:05<00:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.444 | Train Acc: 78.77%\n",
      "\t Val. Loss: 0.521 |  Val. Acc: 72.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 7/15 [00:06<00:07,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.432 | Train Acc: 79.35%\n",
      "\t Val. Loss: 0.510 |  Val. Acc: 76.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 8/15 [00:07<00:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.364 | Train Acc: 85.12%\n",
      "\t Val. Loss: 0.500 |  Val. Acc: 75.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 9/15 [00:08<00:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.356 | Train Acc: 83.62%\n",
      "\t Val. Loss: 0.477 |  Val. Acc: 77.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 10/15 [00:09<00:04,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.304 | Train Acc: 86.28%\n",
      "\t Val. Loss: 0.477 |  Val. Acc: 77.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 11/15 [00:09<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.269 | Train Acc: 88.71%\n",
      "\t Val. Loss: 0.515 |  Val. Acc: 76.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 12/15 [00:10<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.250 | Train Acc: 89.44%\n",
      "\t Val. Loss: 0.640 |  Val. Acc: 74.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 13/15 [00:11<00:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.255 | Train Acc: 89.68%\n",
      "\t Val. Loss: 0.541 |  Val. Acc: 77.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 14/15 [00:12<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.193 | Train Acc: 92.22%\n",
      "\t Val. Loss: 0.545 |  Val. Acc: 77.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:13<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.193 | Train Acc: 91.18%\n",
      "\t Val. Loss: 0.638 |  Val. Acc: 75.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "N_EPOCHS = 15\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "     \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9xqGZ5PK7Aa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xqGZ5PK7Aa0",
    "outputId": "de260ad9-5bbc-4200-d03c-6b729b320e54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut2-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "QMLKG_DD70mH",
   "metadata": {
    "id": "QMLKG_DD70mH"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "jUnpuMM572B_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUnpuMM572B_",
    "outputId": "baa04132-5769-4784-81a1-4b0c9ebb402b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0065348828211426735"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " predict_sentiment(model, \"good amazing wow\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sentiment_kaggle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
